{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "ausDMU81DQVH"
      },
      "source": [
        "# Training Pipeline\n",
        "[run_training_dpo_pipeline.ipynb](https://github.com/shibing624/MedicalGPT/blob/main/run_training_dpo_pipeline.ipynb)    | [Open In Colab](https://colab.research.google.com/github/shibing624/MedicalGPT/blob/main/run_training_dpo_pipeline.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "b3xy8xodDQVI"
      },
      "source": [
        "# Stage 1: Continue Pretraining\n",
        "\n",
        "ç¬¬ä¸€é˜¶æ®µï¼šPT(Continue PreTraining)å¢é‡é¢„è®­ç»ƒï¼Œåœ¨æµ·é‡é¢†åŸŸæ–‡æœ¬æ•°æ®ä¸ŠäºŒæ¬¡é¢„è®­ç»ƒGPTæ¨¡å‹ï¼Œä»¥é€‚é…é¢†åŸŸæ•°æ®åˆ†å¸ƒ\n",
        "\n",
        "æ³¨æ„ï¼š\n",
        "1. æ­¤é˜¶æ®µæ˜¯å¯é€‰çš„ï¼Œå¦‚æœä½ æ²¡æœ‰æµ·é‡é¢†åŸŸæ–‡æœ¬ï¼Œå¯ä»¥è·³è¿‡æ­¤é˜¶æ®µï¼Œç›´æ¥è¿›è¡ŒSFTé˜¶æ®µçš„æœ‰ç›‘ç£å¾®è°ƒ\n",
        "2. æˆ‘å®éªŒå‘ç°ï¼šåšé¢†åŸŸçŸ¥è¯†æ³¨å…¥ï¼ŒSFTæ¯”PTæ›´é«˜æ•ˆï¼Œä¹Ÿå¯ä»¥è·³è¿‡PTé˜¶æ®µ\n",
        "\n",
        "| Stage 1: Continue Pretraining   |  [pretraining.py](https://github.com/shibing624/MedicalGPT/blob/main/pretraining.py) | [run_pt.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_pt.sh)    |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pX1X0ppaDQVI"
      },
      "source": [
        "#### è¯´æ˜ï¼š\n",
        "ä»¥ä¸‹ notebook/colab ä»£ç ä¸ºäº†å¿«é€ŸéªŒè¯è®­ç»ƒä»£ç å¯ç”¨ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†å°sizeçš„ç”Ÿæˆæ¨¡å‹å’Œå°æ ·æœ¬æ•°æ®é›†ï¼Œå®é™…ä½¿ç”¨æ—¶ï¼Œéœ€è¦ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹å’Œæ•°æ®é›†ï¼Œä»¥è·å¾—æ›´å¥½çš„æ•ˆæœã€‚\n",
        "\n",
        "1. ç”Ÿæˆæ¨¡å‹ï¼šä½¿ç”¨çš„æ˜¯Bloomçš„`bigscience/bloomz-560m`\n",
        "2. æ•°æ®é›†ï¼šPTé˜¶æ®µä½¿ç”¨çš„æ˜¯ä¸­æ–‡å¤©é¾™å…«éƒ¨å°è¯´éƒ¨åˆ†æ–‡æœ¬å’Œè‹±æ–‡ä¹¦ç±éƒ¨åˆ†æ–‡æœ¬ï¼Œä½äº`data/pretrain`æ–‡ä»¶å¤¹"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "rAidHRNJDQVJ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJ6iJ6i-DQVJ"
      },
      "source": [
        "## é…ç½®è¿è¡Œç¯å¢ƒ\n",
        "\n",
        "æœ¬åœ°æ‰§è¡Œå¯æ³¨é‡Šä»¥ä¸‹é…ç½®ç¯å¢ƒçš„å‘½ä»¤ï¼Œcolabæ‰§è¡Œè¦æ‰“å¼€æ³¨é‡Šï¼Œç”¨äºé…ç½®ç¯å¢ƒ\n",
        "\n",
        "colabå»ºè®®ä½¿ç”¨T4 GPUè®­ç»ƒï¼Œè®¾ç½®æ–¹å¼ï¼š`ä»£ç æ‰§è¡Œç¨‹åº -> æ›´æ”¹è¿è¡Œæ—¶ç±»å‹ -> è¿è¡Œæ—¶ç±»å‹ï¼šPython3ï¼Œç¡¬ä»¶åŠ é€Ÿå™¨ï¼šGPUï¼ŒGPUç±»å‹ï¼šT4 -> ä¿å­˜`\n",
        "\n",
        "æ­¥éª¤ï¼š\n",
        "1. ä¸‹è½½æœ€æ–°ä»£ç åˆ°æœ¬åœ°\n",
        "2. å®‰è£…ä¾èµ–åŒ…\n",
        "\n",
        "ä¾èµ–åŒ…å¦‚ä¸‹ï¼Œä¿è¯æœ€æ–°ç‰ˆæœ¬ï¼š\n",
        "\n",
        "```\n",
        "loguru\n",
        "transformers\n",
        "sentencepiece\n",
        "datasets\n",
        "tensorboard\n",
        "tqdm\n",
        "peft\n",
        "trl\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5tOhi6ODDQVJ",
        "outputId": "5b200612-3df3-47ba-9778-8152d0234cf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MedicalGPT'...\n",
            "remote: Enumerating objects: 87, done.\u001b[K\n",
            "remote: Counting objects: 100% (87/87), done.\u001b[K\n",
            "remote: Compressing objects: 100% (82/82), done.\u001b[K\n",
            "remote: Total 87 (delta 14), reused 40 (delta 1), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (87/87), 8.54 MiB | 17.60 MiB/s, done.\n",
            "Resolving deltas: 100% (14/14), done.\n",
            "/content/MedicalGPT\n",
            "build_domain_tokenizer.py          inference_multigpu_demo.py  run_dpo.sh\n",
            "chatpdf.py                         inference.py                run_eval_quantize.sh\n",
            "CITATION.cff                       LICENSE                     run_full_sft.sh\n",
            "_config.yml                        merge_peft_adapter.py       run_orpo.sh\n",
            "CONTRIBUTING.md                    merge_tokenizers.py         run_ppo.sh\n",
            "convert_dataset.py                 model_quant.py              run_pt.sh\n",
            "\u001b[0m\u001b[01;34mdata\u001b[0m/                              openai_api.py               run_quant.sh\n",
            "deepspeed_zero_stage2_config.json  orpo_training.py            run_rm.sh\n",
            "deepspeed_zero_stage3_config.json  ppo_training.py             run_sft.sh\n",
            "DISCLAIMER                         pretraining.py              run_training_dpo_pipeline.ipynb\n",
            "\u001b[01;34mdocs\u001b[0m/                              README_EN.md                run_training_ppo_pipeline.ipynb\n",
            "dpo_training.py                    README.md                   supervised_finetuning.py\n",
            "eval_quantize.py                   requirements.txt            template.py\n",
            "fastapi_server_demo.py             reward_modeling.py          validate_jsonl.py\n",
            "gradio_demo.py                     \u001b[01;34mrole_play_data\u001b[0m/             vllm_deployment.sh\n",
            "Collecting accelerate~=0.27.2 (from -r requirements.txt (line 1))\n",
            "  Downloading accelerate-0.27.2-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting datasets>=2.14.6 (from -r requirements.txt (line 2))\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting loguru (from -r requirements.txt (line 3))\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting peft~=0.10.0 (from -r requirements.txt (line 4))\n",
            "  Downloading peft-0.10.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (1.6.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (2.17.1)\n",
            "Requirement already satisfied: tqdm>=4.47.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (4.67.1)\n",
            "Requirement already satisfied: transformers>=4.39.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (4.47.1)\n",
            "Collecting trl~=0.8.3 (from -r requirements.txt (line 10))\n",
            "  Downloading trl-0.8.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting bitsandbytes==0.43.3 (from -r requirements.txt (line 11))\n",
            "  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting tiktoken (from -r requirements.txt (line 12))\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting GPUtil (from -r requirements.txt (line 13))\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from bitsandbytes==0.43.3->-r requirements.txt (line 11)) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bitsandbytes==0.43.3->-r requirements.txt (line 11)) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate~=0.27.2->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate~=0.27.2->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate~=0.27.2->-r requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from accelerate~=0.27.2->-r requirements.txt (line 1)) (0.27.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from accelerate~=0.27.2->-r requirements.txt (line 1)) (0.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->-r requirements.txt (line 2)) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->-r requirements.txt (line 2)) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.14.6->-r requirements.txt (line 2))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->-r requirements.txt (line 2)) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->-r requirements.txt (line 2)) (2.32.3)\n",
            "Collecting xxhash (from datasets>=2.14.6->-r requirements.txt (line 2))\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.14.6->-r requirements.txt (line 2))\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.14.6->-r requirements.txt (line 2))\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->-r requirements.txt (line 2)) (3.11.11)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.69.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (4.25.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (3.1.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.3->-r requirements.txt (line 9)) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.3->-r requirements.txt (line 9)) (0.21.0)\n",
            "Collecting tyro>=0.5.11 (from trl~=0.8.3->-r requirements.txt (line 10))\n",
            "  Downloading tyro-0.9.13-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r requirements.txt (line 2)) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r requirements.txt (line 2)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r requirements.txt (line 2)) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r requirements.txt (line 2)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r requirements.txt (line 2)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r requirements.txt (line 2)) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r requirements.txt (line 2)) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate~=0.27.2->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.14.6->-r requirements.txt (line 2)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.14.6->-r requirements.txt (line 2)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.14.6->-r requirements.txt (line 2)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.14.6->-r requirements.txt (line 2)) (2024.12.14)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.3->-r requirements.txt (line 11)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.3->-r requirements.txt (line 11)) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.3->-r requirements.txt (line 11)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.3->-r requirements.txt (line 11)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.3->-r requirements.txt (line 11)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.3->-r requirements.txt (line 11)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.3->-r requirements.txt (line 11)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.3->-r requirements.txt (line 11)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.3->-r requirements.txt (line 11)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.3->-r requirements.txt (line 11)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.3->-r requirements.txt (line 11)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.3->-r requirements.txt (line 11)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.3->-r requirements.txt (line 11)) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.3->-r requirements.txt (line 11)) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.3->-r requirements.txt (line 11)) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes==0.43.3->-r requirements.txt (line 11)) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->bitsandbytes==0.43.3->-r requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro>=0.5.11->trl~=0.8.3->-r requirements.txt (line 10)) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro>=0.5.11->trl~=0.8.3->-r requirements.txt (line 10)) (13.9.4)\n",
            "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl~=0.8.3->-r requirements.txt (line 10))\n",
            "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro>=0.5.11->trl~=0.8.3->-r requirements.txt (line 10)) (4.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 7)) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.14.6->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.14.6->-r requirements.txt (line 2)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.14.6->-r requirements.txt (line 2)) (2024.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl~=0.8.3->-r requirements.txt (line 10)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl~=0.8.3->-r requirements.txt (line 10)) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl~=0.8.3->-r requirements.txt (line 10)) (0.1.2)\n",
            "Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.10.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.8.6-py3-none-any.whl (245 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m245.2/245.2 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.9.13-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m115.7/115.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7392 sha256=9db4ebf5c6cdb3446ca0adecbafd863c808a8bde0714ddf178d8cf22175201fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/4d/8f/55fb4f7b9b591891e8d3f72977c4ec6c7763b39c19f0861595\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: GPUtil, xxhash, shtab, loguru, fsspec, dill, tiktoken, multiprocess, tyro, datasets, bitsandbytes, accelerate, trl, peft\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.2.1\n",
            "    Uninstalling accelerate-1.2.1:\n",
            "      Successfully uninstalled accelerate-1.2.1\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.14.0\n",
            "    Uninstalling peft-0.14.0:\n",
            "      Successfully uninstalled peft-0.14.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GPUtil-1.4.0 accelerate-0.27.2 bitsandbytes-0.43.3 datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 loguru-0.7.3 multiprocess-0.70.16 peft-0.10.0 shtab-1.7.1 tiktoken-0.8.0 trl-0.8.6 tyro-0.9.13 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!git clone --depth 1 https://github.com/shibing624/MedicalGPT.git\n",
        "%cd MedicalGPT\n",
        "%ls\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY8mLY0TDQVK"
      },
      "source": [
        "## Stage1 å’±ä»¬å¼€å§‹å§\n",
        "\n",
        "è®­ç»ƒæ­¥éª¤å¦‚ä¸‹ï¼š\n",
        "\n",
        "1. ç¡®è®¤è®­ç»ƒé›†\n",
        "2. æ‰§è¡Œè®­ç»ƒè„šæœ¬\n",
        "\n",
        "è®­ç»ƒè„šæœ¬çš„æ‰§è¡Œé€»è¾‘å¦‚ä¸‹ï¼š\n",
        "1. å¯¼å…¥ä¾èµ–åŒ…\n",
        "2. è®¾ç½®å‚æ•°\n",
        "3. å®šä¹‰å„å‡½æ•°å¹¶åŠ è½½è®­ç»ƒé›†\n",
        "4. åŠ è½½æ¨¡å‹å’Œtokenizer\n",
        "5. å¼€å§‹è®­ç»ƒå¹¶è¯„ä¼°\n",
        "6. æŸ¥çœ‹è®­ç»ƒç»“æœ\n",
        "\n",
        "**ä»¥ä¸‹å‚æ•°å¯ä»¥æ ¹æ®ä½ çš„GPUå®é™…æƒ…å†µä¿®æ”¹ï¼Œå½“å‰å‚æ•°æ˜¯æ ¹æ®Colabçš„T4å•å¡GPUï¼ˆ16GBæ˜¾å­˜ï¼‰é…ç½®çš„**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mm_edYKDDQVK",
        "outputId": "0a75584d-aff1-48e7-f90f-90a3ef7c5fce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "en_article_tail500.txt  fever.txt  tianlongbabu.txt\n"
          ]
        }
      ],
      "source": [
        "%ls ./data/pretrain/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "id": "PZHsbVIwDqwa",
        "outputId": "00ccd233-e7b4-49b8-ea13-6715f16c6659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/MedicalGPT'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CP7hoPP8DQVL",
        "outputId": "a9aadf36-9b8b-47f0-f310-c795bbbc38f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
            "2025-01-24 10:36:38.529657: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-24 10:36:38.583864: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-24 10:36:38.599984: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-24 10:36:38.640957: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-01-24 10:36:41.126086: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "\u001b[32m2025-01-24 10:36:43.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mModel args: ModelArguments(model_type='bloom', model_name_or_path='bigscience/bloomz-560m', tokenizer_name_or_path=None, load_in_8bit=False, load_in_4bit=False, cache_dir=None, model_revision='main', hf_hub_token=None, use_fast_tokenizer=False, torch_dtype='float16', device_map='auto', trust_remote_code=True)\u001b[0m\n",
            "\u001b[32m2025-01-24 10:36:43.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mData args: DataArguments(dataset_name=None, dataset_config_name=None, train_file_dir='./data/pretrain', validation_file_dir='./data/pretrain', max_train_samples=20000, max_eval_samples=10, streaming=False, block_size=128, overwrite_cache=False, validation_split_percentage=1, preprocessing_num_workers=1, keep_linebreaks=True)\u001b[0m\n",
            "\u001b[32m2025-01-24 10:36:43.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m379\u001b[0m - \u001b[1mTraining args: Seq2SeqTrainingArguments(\n",
            "_n_gpu=0,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=False,\n",
            "ddp_timeout=30000,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=50,\n",
            "eval_strategy=IntervalStrategy.STEPS,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=steps,\n",
            "fp16=True,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "generation_config=None,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=True,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=True,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.0002,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=outputs-pt-v1/runs/Jan24_10-36-43_f2765b1a2e87,\n",
            "logging_first_step=True,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=10,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=1.0,\n",
            "optim=OptimizerNames.ADAMW_TORCH,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=outputs-pt-v1,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=3,\n",
            "per_device_train_batch_size=3,\n",
            "predict_with_generate=False,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=outputs-pt-v1,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=SaveStrategy.STEPS,\n",
            "save_total_limit=3,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.05,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.01,\n",
            ")\u001b[0m\n",
            "\u001b[32m2025-01-24 10:36:43.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mScript args: ScriptArguments(use_peft=True, target_modules='all', lora_rank=8, lora_dropout=0.05, lora_alpha=16.0, modules_to_save=None, peft_path=None, qlora=False)\u001b[0m\n",
            "\u001b[32m2025-01-24 10:36:43.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m381\u001b[0m - \u001b[1mProcess rank: 0, device: cpu, n_gpu: 0 distributed training: True, 16-bits training: True\u001b[0m\n",
            "\u001b[32m2025-01-24 10:36:45.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m491\u001b[0m - \u001b[1mtrain files: ['./data/pretrain/en_article_tail500.txt', './data/pretrain/tianlongbabu.txt', './data/pretrain/fever.txt']\u001b[0m\n",
            "\u001b[32m2025-01-24 10:36:45.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m501\u001b[0m - \u001b[1meval files: ['./data/pretrain/en_article_tail500.txt', './data/pretrain/tianlongbabu.txt', './data/pretrain/fever.txt']\u001b[0m\n",
            "\u001b[32m2025-01-24 10:36:45.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m533\u001b[0m - \u001b[1mRaw datasets: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 3876\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 3876\n",
            "    })\n",
            "})\u001b[0m\n",
            "\u001b[32m2025-01-24 10:36:46.171\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m596\u001b[0m - \u001b[34m\u001b[1mNum train_samples: 2466\u001b[0m\n",
            "\u001b[32m2025-01-24 10:36:46.171\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m597\u001b[0m - \u001b[34m\u001b[1mTokenized training example:\u001b[0m\n",
            "\u001b[32m2025-01-24 10:36:46.174\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m598\u001b[0m - \u001b[34m\u001b[1mcontract to work in specified mines and mills. There seemed to be no\n",
            "limit to the factories, forges, refineries, and railways that could be\n",
            "built, to the multitudes that could be employed in conquering a\n",
            "continent. As for the future, that was in the hands of Providence!\n",
            "\n",
            "=Business Theories of Politics.=--As the statesmen of Hamilton's school\n",
            "and the planters of Calhoun's had their theories of government and\n",
            "politics, so the leaders in business enterprise had theirs. It was\n",
            "simple and easily stated. \"It is the duty of the government,\u001b[0m\n",
            "\u001b[32m2025-01-24 10:36:46.176\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m610\u001b[0m - \u001b[34m\u001b[1mNum eval_samples: 10\u001b[0m\n",
            "\u001b[32m2025-01-24 10:36:46.176\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m611\u001b[0m - \u001b[34m\u001b[1mTokenized eval example:\u001b[0m\n",
            "\u001b[32m2025-01-24 10:36:46.178\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m612\u001b[0m - \u001b[34m\u001b[1mcontract to work in specified mines and mills. There seemed to be no\n",
            "limit to the factories, forges, refineries, and railways that could be\n",
            "built, to the multitudes that could be employed in conquering a\n",
            "continent. As for the future, that was in the hands of Providence!\n",
            "\n",
            "=Business Theories of Politics.=--As the statesmen of Hamilton's school\n",
            "and the planters of Calhoun's had their theories of government and\n",
            "politics, so the leaders in business enterprise had theirs. It was\n",
            "simple and easily stated. \"It is the duty of the government,\u001b[0m\n",
            "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
            "\u001b[32m2025-01-24 10:36:46.732\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m671\u001b[0m - \u001b[1mFine-tuning method: LoRA(PEFT)\u001b[0m\n",
            "\u001b[32m2025-01-24 10:36:46.732\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m676\u001b[0m - \u001b[1mInit new peft model\u001b[0m\n",
            "\u001b[32m2025-01-24 10:36:46.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m689\u001b[0m - \u001b[1mPeft target_modules: ['dense', 'dense_4h_to_h', 'dense_h_to_4h', 'query_key_value']\u001b[0m\n",
            "\u001b[32m2025-01-24 10:36:46.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m690\u001b[0m - \u001b[1mPeft lora_rank: 8\u001b[0m\n",
            "trainable params: 3,145,728 || all params: 562,360,320 || trainable%: 0.5593794384354857\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py:627: FutureWarning: `is_torch_tpu_available` is deprecated and will be removed in 4.41.0. Please use the `is_torch_xla_available` instead.\n",
            "  warnings.warn(\n",
            "/content/MedicalGPT/pretraining.py:720: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SavePeftModelTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = SavePeftModelTrainer(\n",
            "\u001b[32m2025-01-24 10:36:46.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m735\u001b[0m - \u001b[1m*** Train ***\u001b[0m\n",
            "\u001b[32m2025-01-24 10:36:47.498\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m736\u001b[0m - \u001b[34m\u001b[1mTrain dataloader example: {'input_ids': tensor([[  3101,    842,  10723,   4549,  91164,    355, 208355,   2528,   6940,\n",
            "           2358,   7882,    355,   6200,  28307,    881,  29370,   1938,    355,\n",
            "           1518,  28466,   3476,   1349,   8988,  51631,   5176,   1412,    355,\n",
            "          12395,   1550,   6295,  13212,   1625,  13039,    355,   2350,   8988,\n",
            "          11995,  15441,    355,   1600,  76429,  16552,   5176,  47072,  12391,\n",
            "           2900,    355,   7698,  32697,   2358,    773,  23168,    814, 203457,\n",
            "           1194,   8571,   9768,    355,  16923,    881,  22677,    355,   2405,\n",
            "           3101,  10202,   2630,  53318, 157888,  50254,  25440,    355,  26762,\n",
            "            648,   5176,   8451,   2942,   5362,   9768,    420, 100199,   7046,\n",
            "          10299,  30771,    355,   3763,   5496,   1625, 104352,  18469,    355,\n",
            "          37597, 116140,   1557,   4550,    420,    982,   2761,   4172, 156494,\n",
            "          11534,   4069,   7280,   1497,    355,  10000,   1985,   5510, 151689,\n",
            "          16471,   8988,  19784,   2336,    420,  53843,   1124, 107783,  26762,\n",
            "          73328,  74008,   2079,   8949,   8949,  13139,  19784,    777,    420,\n",
            "           2293,   5176],\n",
            "        [  6051,    420,  59485,  64452,   3483,    881,   4831,  35112, 192442,\n",
            "            777,   1625,    355, 175308,  14675,   3412,  20733,  13214,  22222,\n",
            "          52598,    355,  16647,   2950,   1932,   5530,    373,   5496,   2650,\n",
            "          19994,    355,   6898,   7806,   1170,  11057,  15709,   4719,    420,\n",
            "            842,   2993,   1625,  41397,   3078,  17838,  13599,  57914,   2761,\n",
            "           4172,   7651,   3412,   8513,   4922,    355,   2630,  25410,   7046,\n",
            "          89026,    355,  15462,   1170,  15709,   6271, 189179,  30259,    355,\n",
            "          93021,   7291,   1625,  41397,  70296,    355,   4990,   3427,  50049,\n",
            "            355,  13599,   6561,   1288, 129301,    420,    982,    189, 226598,\n",
            "          14066,   6043,   3412,   5759,    355,   3763,   3574,   2938,   2758,\n",
            "          41397,    355,   2650,   1187,   2382,    881,   4831,  80543,  24619,\n",
            "           6051,  74008,    355,  44327,   3412,  25410,   5472,  16841,    355,\n",
            "           5472,  16841,  57914,   7046,  89026,   9091,   3053, 222519,    355,\n",
            "          18253,   3756,   8577,   5242,   5472,  16841,    726,    373,  44327,\n",
            "           7896,  34275],\n",
            "        [ 14278,  74284,   1224,   5975,  92095,    420,   3427,   2950,  15256,\n",
            "           2950,   2630,  21900,   1697,  26464, 141870,    420,    842, 239328,\n",
            "           2286,    373,   5975,  92095,    644, 133640,   3942,    220,    355,\n",
            "         183353,   1224,  11046,  23408,  10058,    692,    355,   1952, 133015,\n",
            "          52692, 205160,   1170,   9006,  15256,   1170,   9006,  58445,    355,\n",
            "           3105, 133015,  21900,   4697,  15070,    373,  28060,  15256,    982,\n",
            "         162740,  11820,  17476,  61540,  43324,  43324, 141494,    814,  18619,\n",
            "           4162,   6295,  25410,   1190, 205160,   7998,  63779,   9006,  67134,\n",
            "          12613,    355,    644,   5242, 187027,   9344,  45971,    726,  20719,\n",
            "          43074,  46477,   8451,  91262,   4294,  25410,    746,    355,    746,\n",
            "           4077,   5242, 187027,   9344,  45971,    726,  20719,  43074,  34445,\n",
            "           6323,  24194,    420,   3427, 168072,   8095,   2968,  26566, 205160,\n",
            "            355,  64894,  12140,  29948,   6271,  13962,  48898, 205160,  66734,\n",
            "            355,   1194,    881,  30239,   2993,   3078,  13599,  15256,    982,\n",
            "          18619,   4162]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[  3101,    842,  10723,   4549,  91164,    355, 208355,   2528,   6940,\n",
            "           2358,   7882,    355,   6200,  28307,    881,  29370,   1938,    355,\n",
            "           1518,  28466,   3476,   1349,   8988,  51631,   5176,   1412,    355,\n",
            "          12395,   1550,   6295,  13212,   1625,  13039,    355,   2350,   8988,\n",
            "          11995,  15441,    355,   1600,  76429,  16552,   5176,  47072,  12391,\n",
            "           2900,    355,   7698,  32697,   2358,    773,  23168,    814, 203457,\n",
            "           1194,   8571,   9768,    355,  16923,    881,  22677,    355,   2405,\n",
            "           3101,  10202,   2630,  53318, 157888,  50254,  25440,    355,  26762,\n",
            "            648,   5176,   8451,   2942,   5362,   9768,    420, 100199,   7046,\n",
            "          10299,  30771,    355,   3763,   5496,   1625, 104352,  18469,    355,\n",
            "          37597, 116140,   1557,   4550,    420,    982,   2761,   4172, 156494,\n",
            "          11534,   4069,   7280,   1497,    355,  10000,   1985,   5510, 151689,\n",
            "          16471,   8988,  19784,   2336,    420,  53843,   1124, 107783,  26762,\n",
            "          73328,  74008,   2079,   8949,   8949,  13139,  19784,    777,    420,\n",
            "           2293,   5176],\n",
            "        [  6051,    420,  59485,  64452,   3483,    881,   4831,  35112, 192442,\n",
            "            777,   1625,    355, 175308,  14675,   3412,  20733,  13214,  22222,\n",
            "          52598,    355,  16647,   2950,   1932,   5530,    373,   5496,   2650,\n",
            "          19994,    355,   6898,   7806,   1170,  11057,  15709,   4719,    420,\n",
            "            842,   2993,   1625,  41397,   3078,  17838,  13599,  57914,   2761,\n",
            "           4172,   7651,   3412,   8513,   4922,    355,   2630,  25410,   7046,\n",
            "          89026,    355,  15462,   1170,  15709,   6271, 189179,  30259,    355,\n",
            "          93021,   7291,   1625,  41397,  70296,    355,   4990,   3427,  50049,\n",
            "            355,  13599,   6561,   1288, 129301,    420,    982,    189, 226598,\n",
            "          14066,   6043,   3412,   5759,    355,   3763,   3574,   2938,   2758,\n",
            "          41397,    355,   2650,   1187,   2382,    881,   4831,  80543,  24619,\n",
            "           6051,  74008,    355,  44327,   3412,  25410,   5472,  16841,    355,\n",
            "           5472,  16841,  57914,   7046,  89026,   9091,   3053, 222519,    355,\n",
            "          18253,   3756,   8577,   5242,   5472,  16841,    726,    373,  44327,\n",
            "           7896,  34275],\n",
            "        [ 14278,  74284,   1224,   5975,  92095,    420,   3427,   2950,  15256,\n",
            "           2950,   2630,  21900,   1697,  26464, 141870,    420,    842, 239328,\n",
            "           2286,    373,   5975,  92095,    644, 133640,   3942,    220,    355,\n",
            "         183353,   1224,  11046,  23408,  10058,    692,    355,   1952, 133015,\n",
            "          52692, 205160,   1170,   9006,  15256,   1170,   9006,  58445,    355,\n",
            "           3105, 133015,  21900,   4697,  15070,    373,  28060,  15256,    982,\n",
            "         162740,  11820,  17476,  61540,  43324,  43324, 141494,    814,  18619,\n",
            "           4162,   6295,  25410,   1190, 205160,   7998,  63779,   9006,  67134,\n",
            "          12613,    355,    644,   5242, 187027,   9344,  45971,    726,  20719,\n",
            "          43074,  46477,   8451,  91262,   4294,  25410,    746,    355,    746,\n",
            "           4077,   5242, 187027,   9344,  45971,    726,  20719,  43074,  34445,\n",
            "           6323,  24194,    420,   3427, 168072,   8095,   2968,  26566, 205160,\n",
            "            355,  64894,  12140,  29948,   6271,  13962,  48898, 205160,  66734,\n",
            "            355,   1194,    881,  30239,   2993,   3078,  13599,  15256,    982,\n",
            "          18619,   4162]])}\u001b[0m\n",
            "  0% 0/822 [00:00<?, ?it/s]Traceback (most recent call last):\n",
            "  File \"/content/MedicalGPT/pretraining.py\", line 779, in <module>\n",
            "    main()\n",
            "  File \"/content/MedicalGPT/pretraining.py\", line 740, in main\n",
            "    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 2164, in train\n",
            "    return inner_training_loop(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 2524, in _inner_training_loop\n",
            "    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 3654, in training_step\n",
            "    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 3708, in compute_loss\n",
            "    outputs = model(**inputs)\n",
            "              ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/peft/peft_model.py\", line 1129, in forward\n",
            "    return self.base_model(\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py\", line 161, in forward\n",
            "    return self.model.forward(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/bloom/modeling_bloom.py\", line 969, in forward\n",
            "    raise ValueError(f\"Got unexpected arguments: {deprecated_arguments}\")\n",
            "ValueError: Got unexpected arguments: {'num_items_in_batch': 384}\n",
            "  0% 0/822 [00:00<?, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!python pretraining.py \\\n",
        "    --model_type bloom \\\n",
        "    --model_name_or_path bigscience/bloomz-560m \\\n",
        "    --train_file_dir ./data/pretrain \\\n",
        "    --validation_file_dir ./data/pretrain \\\n",
        "    --per_device_train_batch_size 3 \\\n",
        "    --per_device_eval_batch_size 3 \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --use_peft True \\\n",
        "    --seed 42 \\\n",
        "    --fp16 \\\n",
        "    --max_train_samples 20000 \\\n",
        "    --max_eval_samples 10 \\\n",
        "    --num_train_epochs 1 \\\n",
        "    --learning_rate 2e-4 \\\n",
        "    --warmup_ratio 0.05 \\\n",
        "    --weight_decay 0.01 \\\n",
        "    --logging_strategy steps \\\n",
        "    --logging_steps 10 \\\n",
        "    --eval_steps 50 \\\n",
        "    --evaluation_strategy steps \\\n",
        "    --save_steps 500 \\\n",
        "    --save_strategy steps \\\n",
        "    --save_total_limit 3 \\\n",
        "    --gradient_accumulation_steps 1 \\\n",
        "    --preprocessing_num_workers 1 \\\n",
        "    --block_size 128 \\\n",
        "    --group_by_length True \\\n",
        "    --output_dir outputs-pt-v1 \\\n",
        "    --overwrite_output_dir \\\n",
        "    --ddp_timeout 30000 \\\n",
        "    --logging_first_step True \\\n",
        "    --target_modules all \\\n",
        "    --lora_rank 8 \\\n",
        "    --lora_alpha 16 \\\n",
        "    --lora_dropout 0.05 \\\n",
        "    --torch_dtype float16 \\\n",
        "    --device_map auto \\\n",
        "    --report_to tensorboard \\\n",
        "    --ddp_find_unused_parameters False \\\n",
        "    --gradient_checkpointing True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kO3Yi8V5DQVL",
        "outputId": "0c83552d-b238-4225-a0c6-b15cc7f508f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 4.0K\n",
            "drwxr-xr-x 3 root root 4.0K Jan 24 09:40 \u001b[0m\u001b[01;34mruns\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "%ls -lh outputs-pt-v1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTbozqn9DQVL"
      },
      "source": [
        "æ¨¡å‹è®­ç»ƒç»“æœï¼š\n",
        "- ä½¿ç”¨loraè®­ç»ƒæ¨¡å‹ï¼Œåˆ™ä¿å­˜çš„loraæƒé‡æ˜¯`adapter_model.bin`, loraé…ç½®æ–‡ä»¶æ˜¯`adapter_config.json`ï¼Œåˆå¹¶åˆ°base modelçš„æ–¹æ³•è§`merge_peft_adapter.py`\n",
        "- æ—¥å¿—ä¿å­˜åœ¨`output_dir/runs`ç›®å½•ä¸‹ï¼Œå¯ä»¥ä½¿ç”¨tensorboardæŸ¥çœ‹ï¼Œå¯åŠ¨tensorboardæ–¹å¼å¦‚ä¸‹ï¼š`tensorboard --logdir output_dir/runs --host 0.0.0.0 --port 8009`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "ntOocP4YDQVL"
      },
      "source": [
        "loraæ¨¡å‹æƒé‡åˆå¹¶åˆ°base modelï¼Œåˆå¹¶åçš„æ¨¡å‹ä¿å­˜åœ¨`--output_dir`ç›®å½•ä¸‹ï¼Œåˆå¹¶æ–¹æ³•å¦‚ä¸‹ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jCYmJ77dDQVL",
        "outputId": "928e11b4-4ef2-478d-98f7-9a65d14c62e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
            "2025-01-24 09:46:26.946273: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-24 09:46:26.983291: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-24 09:46:26.994120: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-24 09:46:27.021997: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-01-24 09:46:28.856231: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Namespace(model_type='bloom', base_model='bigscience/bloomz-560m', tokenizer_path=None, lora_model='outputs-pt-v1', resize_emb=False, output_dir='merged-pt/', hf_hub_model_id='', hf_hub_token=None)\n",
            "Base model: bigscience/bloomz-560m\n",
            "LoRA model: outputs-pt-v1\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\", line 406, in hf_raise_for_status\n",
            "    response.raise_for_status()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/models.py\", line 1024, in raise_for_status\n",
            "    raise HTTPError(http_error_msg, response=self)\n",
            "requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/outputs-pt-v1/resolve/main/adapter_config.json\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/peft/config.py\", line 143, in from_pretrained\n",
            "    config_file = hf_hub_download(\n",
            "                  ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 860, in hf_hub_download\n",
            "    return _hf_hub_download_to_cache_dir(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 967, in _hf_hub_download_to_cache_dir\n",
            "    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1482, in _raise_on_head_call_error\n",
            "    raise head_call_error\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1374, in _get_metadata_or_catch_error\n",
            "    metadata = get_hf_file_metadata(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1294, in get_hf_file_metadata\n",
            "    r = _request_wrapper(\n",
            "        ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 278, in _request_wrapper\n",
            "    response = _request_wrapper(\n",
            "               ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 302, in _request_wrapper\n",
            "    hf_raise_for_status(response)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\", line 454, in hf_raise_for_status\n",
            "    raise _format(RepositoryNotFoundError, message, response) from e\n",
            "huggingface_hub.errors.RepositoryNotFoundError: 401 Client Error. (Request ID: Root=1-67936176-4701106c7266f1be127cddc5;509f0f0b-38a6-4a98-90b2-123b9a76a520)\n",
            "\n",
            "Repository Not Found for url: https://huggingface.co/outputs-pt-v1/resolve/main/adapter_config.json.\n",
            "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
            "If you are trying to access a private or gated repo, make sure you are authenticated.\n",
            "Invalid username or password.\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/MedicalGPT/merge_peft_adapter.py\", line 121, in <module>\n",
            "    main()\n",
            "  File \"/content/MedicalGPT/merge_peft_adapter.py\", line 59, in main\n",
            "    peft_config = PeftConfig.from_pretrained(lora_model_path)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/peft/config.py\", line 147, in from_pretrained\n",
            "    raise ValueError(f\"Can't find '{CONFIG_NAME}' at '{pretrained_model_name_or_path}'\")\n",
            "ValueError: Can't find 'adapter_config.json' at 'outputs-pt-v1'\n"
          ]
        }
      ],
      "source": [
        "!python merge_peft_adapter.py --model_type bloom \\\n",
        "    --base_model bigscience/bloomz-560m --lora_model outputs-pt-v1 --output_dir merged-pt/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvtlphuqDQVM"
      },
      "outputs": [],
      "source": [
        "%ls -lh merged-pt/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ka_kUZPEDQVM"
      },
      "outputs": [],
      "source": [
        "%cat merged-pt/config.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWsWk3U_DQVM"
      },
      "source": [
        "Stage1 å¢é‡é¢„è®­ç»ƒå®Œæˆã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-15T13:56:17.081153Z",
          "start_time": "2023-06-15T13:56:17.032821Z"
        },
        "id": "adEOh4UtDQVM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "E4BXDh9jDQVM"
      },
      "source": [
        "# Stage 2: Supervised FineTuning\n",
        "\n",
        "ç¬¬äºŒé˜¶æ®µï¼šSFT(Supervised Fine-tuning)æœ‰ç›‘ç£å¾®è°ƒï¼Œæ„é€ æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ï¼Œåœ¨é¢„è®­ç»ƒæ¨¡å‹åŸºç¡€ä¸ŠåšæŒ‡ä»¤ç²¾è°ƒï¼Œä»¥å¯¹é½æŒ‡ä»¤æ„å›¾ï¼Œå¹¶æ³¨å…¥é¢†åŸŸçŸ¥è¯†\n",
        "\n",
        "| Stage 2: Supervised Fine-tuning | [supervised_finetuning.py](https://github.com/shibing624/MedicalGPT/blob/main/supervised_finetuning.py) | [run_sft.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_sft.sh)  |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "GMp-mKCtDQVM"
      },
      "source": [
        "#### è¯´æ˜ï¼š\n",
        "ä»¥ä¸‹ notebook/colab ä»£ç ä¸ºäº†å¿«é€ŸéªŒè¯è®­ç»ƒä»£ç å¯ç”¨ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†å°sizeçš„ç”Ÿæˆæ¨¡å‹å’Œå°æ ·æœ¬æ•°æ®é›†ï¼Œå®é™…ä½¿ç”¨æ—¶ï¼Œéœ€è¦ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹å’Œæ•°æ®é›†ï¼Œä»¥è·å¾—æ›´å¥½çš„æ•ˆæœã€‚\n",
        "\n",
        "1. ç”Ÿæˆæ¨¡å‹ï¼šä½¿ç”¨çš„æ˜¯Bloomçš„`bigscience/bloomz-560m` æˆ–è€… Stage1å¾—åˆ°çš„é¢„è®­ç»ƒæ¨¡å‹\n",
        "2. æ•°æ®é›†ï¼šSFTé˜¶æ®µä½¿ç”¨çš„æ˜¯ä½¿ç”¨çš„æ˜¯Belleçš„1åƒæ¡æŠ½æ ·æ•°æ®ï¼Œä½äº`data/finetune`æ–‡ä»¶å¤¹"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "8qzW_1deDQVN"
      },
      "source": [
        "## Stage2 å’±ä»¬å¼€å§‹å§\n",
        "\n",
        "è®­ç»ƒæ­¥éª¤å¦‚ä¸‹ï¼š\n",
        "\n",
        "1. ç¡®è®¤è®­ç»ƒé›†\n",
        "2. æ‰§è¡Œè®­ç»ƒè„šæœ¬\n",
        "\n",
        "è®­ç»ƒè„šæœ¬çš„æ‰§è¡Œé€»è¾‘å¦‚ä¸‹ï¼š\n",
        "1. å¯¼å…¥ä¾èµ–åŒ…\n",
        "2. è®¾ç½®å‚æ•°\n",
        "3. å®šä¹‰å„å‡½æ•°å¹¶åŠ è½½è®­ç»ƒé›†\n",
        "4. åŠ è½½æ¨¡å‹å’Œtokenizer\n",
        "5. å¼€å§‹è®­ç»ƒå¹¶è¯„ä¼°\n",
        "6. æŸ¥çœ‹è®­ç»ƒç»“æœ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-15T13:58:38.966506Z",
          "start_time": "2023-06-15T13:58:38.778132Z"
        },
        "id": "wPmSTQ5ZDQVN"
      },
      "outputs": [],
      "source": [
        "%ls ./data/finetune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8J4NOmTDQVN"
      },
      "outputs": [],
      "source": [
        "!python supervised_finetuning.py \\\n",
        "    --model_type bloom \\\n",
        "    --model_name_or_path merged-pt \\\n",
        "    --train_file_dir ./data/finetune \\\n",
        "    --validation_file_dir ./data/finetune \\\n",
        "    --per_device_train_batch_size 4 \\\n",
        "    --per_device_eval_batch_size 4 \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --use_peft True \\\n",
        "    --fp16 \\\n",
        "    --max_train_samples 1000 \\\n",
        "    --max_eval_samples 10 \\\n",
        "    --num_train_epochs 1 \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --warmup_ratio 0.05 \\\n",
        "    --weight_decay 0.05 \\\n",
        "    --logging_strategy steps \\\n",
        "    --logging_steps 10 \\\n",
        "    --eval_steps 50 \\\n",
        "    --evaluation_strategy steps \\\n",
        "    --save_steps 500 \\\n",
        "    --save_strategy steps \\\n",
        "    --save_total_limit 3 \\\n",
        "    --gradient_accumulation_steps 1 \\\n",
        "    --preprocessing_num_workers 1 \\\n",
        "    --output_dir outputs-sft-v1 \\\n",
        "    --overwrite_output_dir \\\n",
        "    --ddp_timeout 30000 \\\n",
        "    --logging_first_step True \\\n",
        "    --target_modules all \\\n",
        "    --lora_rank 8 \\\n",
        "    --lora_alpha 16 \\\n",
        "    --lora_dropout 0.05 \\\n",
        "    --torch_dtype float16 \\\n",
        "    --device_map auto \\\n",
        "    --report_to tensorboard \\\n",
        "    --ddp_find_unused_parameters False \\\n",
        "    --gradient_checkpointing True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qCEXRtNDQVN"
      },
      "outputs": [],
      "source": [
        "%ls -lh outputs-sft-v1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Ie-imDoRDQVN"
      },
      "source": [
        "æ¨¡å‹è®­ç»ƒç»“æœï¼š\n",
        "- ä½¿ç”¨loraè®­ç»ƒæ¨¡å‹ï¼Œåˆ™ä¿å­˜çš„loraæƒé‡æ˜¯`adapter_model.bin`, loraé…ç½®æ–‡ä»¶æ˜¯`adapter_config.json`ï¼Œåˆå¹¶åˆ°base modelçš„æ–¹æ³•è§`merge_peft_adapter.py`\n",
        "- æ—¥å¿—ä¿å­˜åœ¨`output_dir/runs`ç›®å½•ä¸‹ï¼Œå¯ä»¥ä½¿ç”¨tensorboardæŸ¥çœ‹ï¼Œå¯åŠ¨tensorboardæ–¹å¼å¦‚ä¸‹ï¼š`tensorboard --logdir output_dir/runs --host 0.0.0.0 --port 8009`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "i1rLyahhDQVN"
      },
      "source": [
        "loraæ¨¡å‹æƒé‡åˆå¹¶åˆ°base modelï¼Œåˆå¹¶åçš„æ¨¡å‹ä¿å­˜åœ¨`--output_dir`ç›®å½•ä¸‹ï¼Œåˆå¹¶æ–¹æ³•å¦‚ä¸‹ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uacBQUL_DQVN"
      },
      "outputs": [],
      "source": [
        "!python merge_peft_adapter.py --model_type bloom \\\n",
        "    --base_model merged-pt --lora_model outputs-sft-v1 --output_dir ./merged-sft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdJrplhwDQVO"
      },
      "outputs": [],
      "source": [
        "%ls -lh merged-sft/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmC_QQ42DQVO"
      },
      "outputs": [],
      "source": [
        "%cat merged-sft/config.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "QG2hcEmPDQVO"
      },
      "source": [
        "Stage2 SFTè®­ç»ƒå®Œæˆã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-15T14:07:40.752635Z",
          "start_time": "2023-06-15T14:07:40.731186Z"
        },
        "id": "W7yaI6FbDQVO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Ce9-lfoNDQVO"
      },
      "source": [
        "# Stage 3: DPO(Direct Preference Optimization)\n",
        "\n",
        "ç¬¬ä¸‰é˜¶æ®µï¼šDPO(Direct Preference Optimization)ç›´æ¥åå¥½ä¼˜åŒ–ï¼ŒDPOé€šè¿‡ç›´æ¥ä¼˜åŒ–è¯­è¨€æ¨¡å‹æ¥å®ç°å¯¹å…¶è¡Œä¸ºçš„ç²¾ç¡®æ§åˆ¶ï¼Œè€Œæ— éœ€ä½¿ç”¨å¤æ‚çš„å¼ºåŒ–å­¦ä¹ ï¼Œä¹Ÿå¯ä»¥æœ‰æ•ˆå­¦ä¹ åˆ°äººç±»åå¥½ï¼ŒDPOç›¸è¾ƒäºRLHFæ›´å®¹æ˜“å®ç°ä¸”æ˜“äºè®­ç»ƒï¼Œæ•ˆæœæ›´å¥½\n",
        "\n",
        "| Stage 3: Direct Preference Optimization        |  [dpo_training.py](https://github.com/shibing624/MedicalGPT/blob/main/dpo_training.py) | [run_dpo.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_dpo.sh)    |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "NzaKHlX3DQVO"
      },
      "source": [
        "#### è¯´æ˜ï¼š\n",
        "ä»¥ä¸‹ notebook/colab ä»£ç ä¸ºäº†å¿«é€ŸéªŒè¯è®­ç»ƒä»£ç å¯ç”¨ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†å°sizeçš„ç”Ÿæˆæ¨¡å‹å’Œå°æ ·æœ¬æ•°æ®é›†ï¼Œå®é™…ä½¿ç”¨æ—¶ï¼Œéœ€è¦ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹å’Œæ•°æ®é›†ï¼Œä»¥è·å¾—æ›´å¥½çš„æ•ˆæœã€‚\n",
        "\n",
        "1. ç”Ÿæˆæ¨¡å‹ï¼šä½¿ç”¨çš„æ˜¯Bloomçš„`bigscience/bloomz-560m` æˆ–è€… Stage2å¾—åˆ°çš„SFTæ¨¡å‹\n",
        "2. æ•°æ®é›†ï¼šDPOé˜¶æ®µä½¿ç”¨çš„æ˜¯åŒ»ç–—rewardæ•°æ®ï¼ŒæŠ½æ ·äº†500æ¡ï¼Œä½äº`data/reward`æ–‡ä»¶å¤¹"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "YtQoYNM4DQVO"
      },
      "source": [
        "## Stage3 å’±ä»¬å¼€å§‹å§\n",
        "\n",
        "è®­ç»ƒæ­¥éª¤å¦‚ä¸‹ï¼š\n",
        "\n",
        "1. ç¡®è®¤è®­ç»ƒé›†\n",
        "2. æ‰§è¡Œè®­ç»ƒè„šæœ¬\n",
        "\n",
        "è®­ç»ƒè„šæœ¬çš„æ‰§è¡Œé€»è¾‘å¦‚ä¸‹ï¼š\n",
        "1. å¯¼å…¥ä¾èµ–åŒ…\n",
        "2. è®¾ç½®å‚æ•°\n",
        "3. å®šä¹‰å„å‡½æ•°å¹¶åŠ è½½è®­ç»ƒé›†\n",
        "4. åŠ è½½æ¨¡å‹å’Œtokenizer\n",
        "5. å¼€å§‹è®­ç»ƒå¹¶è¯„ä¼°\n",
        "6. æŸ¥çœ‹è®­ç»ƒç»“æœ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5RdhbJVDQVO"
      },
      "outputs": [],
      "source": [
        "%ls ./data/reward/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NHiCoEiDQVP"
      },
      "outputs": [],
      "source": [
        "!python dpo_training.py \\\n",
        "    --model_type bloom \\\n",
        "    --model_name_or_path ./merged-sft \\\n",
        "    --train_file_dir ./data/reward \\\n",
        "    --validation_file_dir ./data/reward \\\n",
        "    --per_device_train_batch_size 3 \\\n",
        "    --per_device_eval_batch_size 1 \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --use_peft True \\\n",
        "    --max_train_samples 1000 \\\n",
        "    --max_eval_samples 500 \\\n",
        "    --max_steps 100 \\\n",
        "    --eval_steps 10 \\\n",
        "    --save_steps 50 \\\n",
        "    --max_source_length 256 \\\n",
        "    --max_target_length 256 \\\n",
        "    --output_dir outputs-dpo-v1 \\\n",
        "    --target_modules all \\\n",
        "    --lora_rank 8 \\\n",
        "    --lora_alpha 16 \\\n",
        "    --lora_dropout 0.05 \\\n",
        "    --torch_dtype float16 \\\n",
        "    --fp16 True \\\n",
        "    --device_map auto \\\n",
        "    --report_to tensorboard \\\n",
        "    --remove_unused_columns False \\\n",
        "    --gradient_checkpointing True \\\n",
        "    --cache_dir ./cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tg_xB90DQVP"
      },
      "outputs": [],
      "source": [
        "%ls -lh outputs-dpo-v1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "gsU2TaPkDQVP"
      },
      "source": [
        "æ¨¡å‹è®­ç»ƒç»“æœï¼š\n",
        "- ä½¿ç”¨loraè®­ç»ƒæ¨¡å‹ï¼Œåˆ™ä¿å­˜çš„loraæƒé‡æ˜¯`adapter_model.bin`, loraé…ç½®æ–‡ä»¶æ˜¯`adapter_config.json`ï¼Œåˆå¹¶åˆ°base modelçš„æ–¹æ³•è§`merge_peft_adapter.py`\n",
        "- æ—¥å¿—ä¿å­˜åœ¨`output_dir/runs`ç›®å½•ä¸‹ï¼Œå¯ä»¥ä½¿ç”¨tensorboardæŸ¥çœ‹ï¼Œå¯åŠ¨tensorboardæ–¹å¼å¦‚ä¸‹ï¼š`tensorboard --logdir output_dir/runs --host 0.0.0.0 --port 8009`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "iq7o3jntDQVP"
      },
      "source": [
        "loraæ¨¡å‹æƒé‡åˆå¹¶åˆ°base modelï¼Œåˆå¹¶åçš„æ¨¡å‹ä¿å­˜åœ¨`--output_dir`ç›®å½•ä¸‹ï¼Œåˆå¹¶æ–¹æ³•å¦‚ä¸‹ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GSKeB6IDQVP"
      },
      "outputs": [],
      "source": [
        "!python merge_peft_adapter.py --model_type bloom \\\n",
        "    --base_model merged-sft --lora_model outputs-dpo-v1 --output_dir merged-dpo/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zhfjgfw7DQVT"
      },
      "outputs": [],
      "source": [
        "%ls -lh merged-dpo/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abPdUfM0DQVT"
      },
      "outputs": [],
      "source": [
        "%cat merged-dpo/config.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "B7mZiNXpDQVT"
      },
      "source": [
        "Stage3 åå¥½å»ºæ¨¡ç¬¬ä¸€æ¬¡è®­ç»ƒå®Œæˆã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "TvhrPO5ODQVT"
      },
      "source": [
        "**è‡³æ­¤ä¸€ä¸ªå®Œæ•´çš„è®­ç»ƒæµç¨‹æ¼”ç¤ºå®Œæˆã€‚**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-26T12:34:29.658428Z",
          "start_time": "2023-06-26T12:34:29.620609Z"
        },
        "id": "EcVdKdyzDQVU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "UfBT5eLzDQVU"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-26T12:35:00.864463Z",
          "start_time": "2023-06-26T12:34:47.802087Z"
        },
        "id": "PvZyS1QwDQVU"
      },
      "outputs": [],
      "source": [
        "!python inference.py --model_type bloom --base_model merged-dpo\n",
        "# æˆ–åœ¨shellä¸­è¿è¡Œ\n",
        "# python inference.py --model_type bloom --base_model merged-dpo --interactive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "4iE1-Tr2DQVU"
      },
      "source": [
        "Input:ä»‹ç»ä¸‹å—äº¬\n",
        "Response:  å—äº¬å¸‚ä½äºæ±Ÿè‹çœè¥¿å—éƒ¨ï¼Œæ˜¯å…¨å›½é¦–æ‰¹å†å²æ–‡åŒ–ååŸã€å›½å®¶ä¸­å¿ƒåŸå¸‚å’Œè‡ªç”±è´¸æ˜“è¯•éªŒåŒºã€‚\n",
        "\n",
        "å®Œã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eqciigNDQVU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "f34eed0bebedfc4b6ee51ced43d2c030fe3b92f13c149d072205ca200a67b1ec"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}